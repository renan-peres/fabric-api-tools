{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"fabric_remote_tools: OneLake CRUD Operations\"\n",
    "author: \"Renan Peres\"\n",
    "date: \"July 01, 2024\"\n",
    "format:\n",
    "    html:\n",
    "        theme: \n",
    "            light: flatly\n",
    "            dark: darkly\n",
    "        highlight-style: dracula\n",
    "        code-fold: show\n",
    "        code-tools: \n",
    "            source: true\n",
    "            toggle: true\n",
    "            # caption: none\n",
    "        code-copy: true\n",
    "        code-overflow: wrap\n",
    "        smooth-scroll: true       \n",
    "        page-layout: full\n",
    "        toc: true\n",
    "        toc-location: left\n",
    "        lightbox: true\n",
    "    ipynb:\n",
    "        output-file: output-file: \"fabric_remote_tools-OneLake-CRUD-Operations.ipynb\"\n",
    "        highlight-style: dracula\n",
    "        code-fold: show\n",
    "    pdf: default\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install https://github.com/renan-peres/fabric-remote-tools/raw/main/fabric_remote_tools-0.1.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Modules & Authenticate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabric_remote_tools import FabricAuth, OneLakeUtils\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load Fabric Environmet Variables (.env File)\n",
    "account_name = os.getenv(\"ACCOUNT_NAME\")\n",
    "workspace_id = os.getenv(\"WORKSPACE_ID\")\n",
    "lakehouse_id = os.getenv(\"LAKEHOUSE_ID\")\n",
    "\n",
    "# Get Authentication Token\n",
    "token = FabricAuth.get_DefaultAzureCredential()\n",
    "\n",
    "# Get File System Client\n",
    "file_system_client = FabricAuth.get_FileSystemClient(token, account_name, workspace_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Write to Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Local Tables (Delta)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading local Delta Table '../assets/data/Tables/venture_funding_deals_delta_partitioned' to 'Tables/local_venture_funding_deals_delta_partitioned'\n",
      "Successfully uploaded 40 out of 40 files to 'Tables/local_venture_funding_deals_delta_partitioned'\n",
      "Uploading multiple tables from '../assets/data/Tables' to 'Tables/'\n",
      "Successfully uploaded 2 out of 2 files to 'Tables/venture_funding_deals_delta'\n",
      "Successfully uploaded 40 out of 40 files to 'Tables/venture_funding_deals_delta_partitioned'\n"
     ]
    }
   ],
   "source": [
    "# Single Table\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Tables/venture_funding_deals_delta_partitioned\",\n",
    "    target_path=\"Tables/local_venture_funding_deals_delta_partitioned\"\n",
    ")\n",
    "\n",
    "# Multiple Tables in a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Tables\",\n",
    "    target_path=\"Tables/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Local Files/Folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files\",\n",
    "    target_path=\"Files/\"\n",
    ")\n",
    "\n",
    "# Individual Subfolder inside a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files/Contoso\",\n",
    "    target_path=\"Files/Contoso\"\n",
    ")\n",
    "\n",
    "# Specific File in a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files/Contoso/contoso_sales.csv\",\n",
    "    target_path=\"Files/Contoso/contoso_sales.csv\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GitHub (Public Repo)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole GitHub repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Files/GitHub/Polars-Cookbook\"\n",
    ")\n",
    "\n",
    "# Single Table (Delta) in Repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Tables/github_venture_funding_deals_delta\",\n",
    "    folder_path=\"data/venture_funding_deals_delta\"\n",
    ")\n",
    "\n",
    "# Specific folder from GitHub repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Files/GitHub/data\",\n",
    "    folder_path=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GitHub (Private Repo)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_token = os.getenv(\"GH_PERSONAL_ACCESS_TOKEN\")\n",
    "github_username = os.getenv(\"GH_USERNAME\")\n",
    "gh_repo_name = os.getenv(\"GH_REPO_NAME\")\n",
    "\n",
    "# Whole GitHub private repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github_private\",\n",
    "    github_token=github_token,\n",
    "    github_username=github_username,\n",
    "    repo_name=gh_repo_name,\n",
    "    target_path=f\"Files/GitHub/{gh_repo_name}\"\n",
    ")\n",
    "\n",
    "# Specific folder from GitHub private repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github_private\",\n",
    "    github_token=github_token,\n",
    "    github_username=github_username,\n",
    "    repo_name=gh_repo_name,\n",
    "    target_path=\"Files/GitHub/data\",\n",
    "    folder_path=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Azure DevOps (Private Repo)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_url = os.getenv(\"ADO_ORGANIZATIONAL_URL\")\n",
    "personal_access_token = os.getenv(\"ADO_PERSONAL_ACCESS_TOKEN\")\n",
    "project_name = os.getenv(\"ADO_PROJECT_NAME\")\n",
    "repo_name = os.getenv(\"ADO_REPO_NAME\")\n",
    "\n",
    "# Whole Azure DevOps repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"azure_devops\",\n",
    "    project_name=project_name,\n",
    "    repo_name=repo_name,\n",
    "    organization_url=organization_url,\n",
    "    personal_access_token=personal_access_token,\n",
    "    target_path=f\"Files/AzureDevOps/{repo_name}\",\n",
    ")\n",
    "\n",
    "# Specific folder from Azure DevOps repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"azure_devops\",\n",
    "    project_name=project_name,\n",
    "    repo_name=repo_name,\n",
    "    organization_url=organization_url,\n",
    "    personal_access_token=personal_access_token,\n",
    "    target_path=\"Files/AzureDevOps/data\",\n",
    "    folder_path=\"/data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **List Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List All Items in Lakehouse\n",
    "OneLakeUtils.list_items(\n",
    "    file_system_client=file_system_client\n",
    "    ,lakehouse_id=lakehouse_id\n",
    "    ,target_directory_path=\"Tables\" # Tables or Files\n",
    "    #  ,print_output= True # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DeltaLake Table Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read Table from Lakehouse into a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────────┬────────────────┬───────────────────────┬─────────────────┬─────────────────────────┬───────────────┐\n",
       "│     Company     │     Amount     │    Lead investors     │    Valuation    │        Industry         │ Date reported │\n",
       "│     varchar     │    varchar     │        varchar        │     varchar     │         varchar         │    varchar    │\n",
       "├─────────────────┼────────────────┼───────────────────────┼─────────────────┼─────────────────────────┼───────────────┤\n",
       "│ Stripe          │ $6,500,000,000 │ n/a                   │ $50,000,000,000 │ Fintech                 │ 3/15/23       │\n",
       "│ Inflection AI   │ $1,300,000,000 │ Microsoft, Reid Hof…  │ $4,000,000,000  │ Artificial intelligence │ 6/29/23       │\n",
       "│ Anthropic       │ $1,250,000,000 │ Amazon                │ $4,000,000,000  │ Artificial intelligence │ 9/25/23       │\n",
       "│ Lessen          │ $500,000,000   │ n/a                   │ $2,000,000,000  │ Real estate             │ 1/11/23       │\n",
       "│ Databricks      │ $500,000,000   │ funds and accounts …  │ $43,000,000,000 │ Data                    │ 9/14/23       │\n",
       "│ Anthropic       │ $450,000,000   │ Spark Capital         │ $4,100,000,000  │ Artificial intelligence │ 5/23/23       │\n",
       "│ Adept AI        │ $350,000,000   │ General Catalyst, S…  │ $1,000,000,000  │ Artificial intelligence │ 3/14/23       │\n",
       "│ Axiom Space     │ $350,000,000   │ Aljazira Capital, B…  │ $1,000,000,000  │ Space tech              │ 8/21/23       │\n",
       "│ Zipline         │ $330,000,000   │ n/a                   │ $4,200,000,000  │ Drones                  │ 4/28/23       │\n",
       "│ Our Next Energy │ $300,000,000   │ Franklin Templeton …  │ $1,200,000,000  │ Energy                  │ 2/1/23        │\n",
       "│     ·           │      ·         │   ·                   │  ·              │   ·                     │   ·           │\n",
       "│     ·           │      ·         │   ·                   │  ·              │   ·                     │   ·           │\n",
       "│     ·           │      ·         │   ·                   │  ·              │   ·                     │   ·           │\n",
       "│ Anthropic       │ $300,000,000   │ Google                │ NULL            │ Artificial intelligence │ 2/3/23        │\n",
       "│ Wiz             │ $300,000,000   │ Lightspeed Venture …  │ $10,000,000,000 │ Cybersecurity           │ 2/27/23       │\n",
       "│ OpenAI          │ $300,000,000   │ n/a                   │ $2,800,000,000  │ Artificial intelligence │ 4/28/23       │\n",
       "│ Madhive         │ $300,000,000   │ Goldman Sachs Asset…  │ $1,000,000,000  │ Advertising             │ 6/13/23       │\n",
       "│ Ramp            │ $300,000,000   │ n/a                   │ $5,800,000,000  │ Fintech                 │ 8/23/23       │\n",
       "│ Sierra Space    │ $290,000,000   │ MUFG, Kanematsu Cor…  │ $5,300,000,000  │ Space                   │ 9/26/23       │\n",
       "│ Clear Street    │ $270,000,000   │ Prysm Capital         │ $2,000,000,000  │ Fintech                 │ 4/11/23       │\n",
       "│ Skims           │ $270,000,000   │ Wellington Management │ $4,000,000,000  │ Apparel                 │ 7/19/23       │\n",
       "│ Aledade         │ $260,000,000   │ Lightspeed Venture …  │ $3,500,000,000  │ Health care             │ 6/21/23       │\n",
       "│ Indigo          │ $250,000,000   │ Flagship Pioneering…  │ na              │ Agriculture             │ 9/15/23       │\n",
       "├─────────────────┴────────────────┴───────────────────────┴─────────────────┴─────────────────────────┴───────────────┤\n",
       "│ 40 rows (20 shown)                                                                                         6 columns │\n",
       "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fabric_remote_tools import FabricAuth, OneLakeUtils\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "\n",
    "# Authenticate and obtain access token\n",
    "file_system_client = FabricAuth().get_ClientSecretCredential()\n",
    "\n",
    "# Read Table from Lakehouse into Dataframe\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\")\n",
    "lakehouse_name = os.getenv(\"LAKEHOUSE_NAME\")\n",
    "table_name = \"Tables/venture_funding_deals_delta\"\n",
    "table_path = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/{lakehouse_name}.Lakehouse/{table_name}\"\n",
    "\n",
    "df = OneLakeUtils().read_deltalake(\n",
    "    file_system_client=file_system_client,\n",
    "    table_path=table_path,\n",
    "    engine='duckdb',  # Supported options: 'duckdb', 'polars'\n",
    "    # version=11,  # Optional: specify the version to read\n",
    "    # row_limit=10  # Optional\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query DataFrame with DuckDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install magic_duckdb --upgrade --quiet\n",
    "%load_ext magic_duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>null</th>\n",
       "      <th>key</th>\n",
       "      <th>default</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amount</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead investors</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valuation</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Industry</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Date reported</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      column_name column_type null   key default extra\n",
       "0         Company     VARCHAR  YES  None    None  None\n",
       "1          Amount     VARCHAR  YES  None    None  None\n",
       "2  Lead investors     VARCHAR  YES  None    None  None\n",
       "3       Valuation     VARCHAR  YES  None    None  None\n",
       "4        Industry     VARCHAR  YES  None    None  None\n",
       "5   Date reported     VARCHAR  YES  None    None  None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dql\n",
    "PRAGMA disable_print_progress_bar;\n",
    "SUMMARIZE df;\n",
    "DESCRIBE SELECT * FROM df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count\n",
       "0     20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dql\n",
    "CREATE OR REPLACE TABLE df_tranf AS \n",
    "    SELECT *\n",
    "    FROM df\n",
    "    LIMIT 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write DataFrame to Lakehouse as a Delta Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deltalake.writer import write_deltalake\n",
    "import duckdb\n",
    "import pyarrow\n",
    "import polars as pl\n",
    "\n",
    "# Write DataFrame to Lakehouse\n",
    "write_deltalake(\n",
    "    table_or_uri=table_path\n",
    "    ,storage_options=file_system_client\n",
    "    # ,data=df.to_arrow() # Polars DF\n",
    "    ,data=duckdb.sql(\"SELECT * FROM df_tranf\").arrow() # DuckDB (arrow DF)\n",
    "    ,mode=\"append\" # Supported options: 'append', 'overwrite'\n",
    "    ,engine=\"rust\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DESCRIBE HISTORY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>clientVersion</th>\n",
       "      <th>version</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>engineInfo</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>txnId</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-04 12:31:35.831</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Append'}</td>\n",
       "      <td>delta-rs.0.18.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-03 19:21:49.276</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Append'}</td>\n",
       "      <td>delta-rs.0.18.1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-03 19:21:42.788</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Overwrite'}</td>\n",
       "      <td>delta-rs.0.18.1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-02 19:52:55.075</td>\n",
       "      <td>VACUUM END</td>\n",
       "      <td>{'status': 'COMPLETED'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SnapshotIsolation</td>\n",
       "      <td>True</td>\n",
       "      <td>Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...</td>\n",
       "      <td>{'numDeletedFiles': '0', 'numVacuumedDirectori...</td>\n",
       "      <td>4ebe44b4-d133-4e06-b659-1deb812dee77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-02 19:52:53.249</td>\n",
       "      <td>VACUUM START</td>\n",
       "      <td>{'retentionCheckEnabled': True, 'defaultRetent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SnapshotIsolation</td>\n",
       "      <td>True</td>\n",
       "      <td>Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...</td>\n",
       "      <td>{'numFilesToDelete': '0', 'sizeOfDataToDelete'...</td>\n",
       "      <td>60f1f933-7958-47c1-bf8e-46031dac75f2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp     operation  \\\n",
       "0 2024-07-04 12:31:35.831         WRITE   \n",
       "1 2024-07-03 19:21:49.276         WRITE   \n",
       "2 2024-07-03 19:21:42.788         WRITE   \n",
       "3 2024-07-02 19:52:55.075    VACUUM END   \n",
       "4 2024-07-02 19:52:53.249  VACUUM START   \n",
       "\n",
       "                                 operationParameters    clientVersion  \\\n",
       "0                                 {'mode': 'Append'}  delta-rs.0.18.0   \n",
       "1                                 {'mode': 'Append'}  delta-rs.0.18.1   \n",
       "2                              {'mode': 'Overwrite'}  delta-rs.0.18.1   \n",
       "3                            {'status': 'COMPLETED'}              NaN   \n",
       "4  {'retentionCheckEnabled': True, 'defaultRetent...              NaN   \n",
       "\n",
       "   version  readVersion     isolationLevel isBlindAppend  \\\n",
       "0       10          NaN                NaN           NaN   \n",
       "1        9          NaN                NaN           NaN   \n",
       "2        8          NaN                NaN           NaN   \n",
       "3        7          6.0  SnapshotIsolation          True   \n",
       "4        6          5.0  SnapshotIsolation          True   \n",
       "\n",
       "                                          engineInfo  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...   \n",
       "4  Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...   \n",
       "\n",
       "                                    operationMetrics  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  {'numDeletedFiles': '0', 'numVacuumedDirectori...   \n",
       "4  {'numFilesToDelete': '0', 'sizeOfDataToDelete'...   \n",
       "\n",
       "                                  txnId tags  \n",
       "0                                   NaN  NaN  \n",
       "1                                   NaN  NaN  \n",
       "2                                   NaN  NaN  \n",
       "3  4ebe44b4-d133-4e06-b659-1deb812dee77  NaN  \n",
       "4  60f1f933-7958-47c1-bf8e-46031dac75f2  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deltalake import DeltaTable\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the DeltaTable\n",
    "dt = DeltaTable(table_path)\n",
    "\n",
    "# Retrieve the full history of the DeltaTable\n",
    "history = dt.history()\n",
    "\n",
    "# Convert the history list to a pandas DataFrame\n",
    "history_df = pd.DataFrame(history)\n",
    "\n",
    "# Parse the timestamp column\n",
    "history_df['timestamp'] = pd.to_datetime(history_df['timestamp'], unit='ms')\n",
    "\n",
    "# Display the DataFrame, sorted by version in descending order\n",
    "display(history_df.sort_values(by='version', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Download Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading 'Tables/venture_funding_deals': name 'OneLakeUtils' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Download a single table\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    target_file_path=\"Tables/venture_funding_deals\"\n",
    ")\n",
    "\n",
    "# Download a single file\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    target_file_path=\"Files/Contoso/contoso_sales.csv\"\n",
    ")\n",
    "\n",
    "# Download a Files subfolder\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    target_file_path=\"Files/Contoso/\"\n",
    ")\n",
    "\n",
    "# Download all tables\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    target_file_path=\"Tables/\"\n",
    ")\n",
    "\n",
    "# Download all files\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    target_file_path=\"Files/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Delete Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a single table\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Tables/venture_funding_deals_delta\"\n",
    ")\n",
    "\n",
    "# Delete a single file\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Files/Contoso/contoso_sales.csv\"\n",
    ")\n",
    "\n",
    "# Delete a subfolder\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Files/Contoso\"\n",
    ")\n",
    "\n",
    "# Delete all tables\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Tables/\"\n",
    ")\n",
    "\n",
    "# Delete all files\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Files/\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
