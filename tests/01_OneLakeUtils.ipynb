{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"fabric_remote_tools: OneLake CRUD Operations\"\n",
    "author: \"Renan Peres\"\n",
    "date: \"July 01, 2024\"\n",
    "format:\n",
    "    html:\n",
    "        theme: \n",
    "            light: flatly\n",
    "            dark: darkly\n",
    "        highlight-style: dracula\n",
    "        code-fold: show\n",
    "        code-tools: \n",
    "            source: true\n",
    "            toggle: true\n",
    "            # caption: none\n",
    "        code-copy: true\n",
    "        code-overflow: wrap\n",
    "        smooth-scroll: true       \n",
    "        page-layout: full\n",
    "        toc: true\n",
    "        toc-location: left\n",
    "        lightbox: true\n",
    "    ipynb:\n",
    "        output-file: output-file: \"fabric_remote_tools-OneLake-CRUD-Operations.ipynb\"\n",
    "        highlight-style: dracula\n",
    "        code-fold: show\n",
    "    pdf: default\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install https://github.com/renan-peres/fabric-remote-tools/raw/main/fabric_remote_tools-0.1.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Modules & Authenticate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabric_remote_tools import FabricAuth, OneLakeUtils\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load Fabric Environmet Variables (.env File)\n",
    "account_name = os.getenv(\"ACCOUNT_NAME\")\n",
    "workspace_id = os.getenv(\"WORKSPACE_ID\")\n",
    "lakehouse_id = os.getenv(\"LAKEHOUSE_ID\")\n",
    "\n",
    "# Get Authentication Token\n",
    "token = FabricAuth.get_DefaultAzureCredential()\n",
    "\n",
    "# Get File System Client\n",
    "file_system_client = FabricAuth.get_FileSystemClient(token, account_name, workspace_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Write to Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Local Tables (Delta)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Table\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Tables/venture_funding_deals_delta_partitioned\",\n",
    "    target_path=\"Tables/local_venture_funding_deals_delta_partitioned\"\n",
    ")\n",
    "\n",
    "# Multiple Tables in a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Tables\",\n",
    "    target_path=\"Tables/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Local Files/Folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading local folder '../assets/data/Files' to 'Files/'\n",
      "Successfully uploaded 7 out of 7 files to 'Files/'\n",
      "Uploading local folder '../assets/data/Files/Contoso' to 'Files/Contoso'\n",
      "Successfully uploaded 1 out of 1 files to 'Files/Contoso'\n",
      "Uploading local file '../assets/data/Files/Contoso/contoso_sales.csv' to 'Files/Contoso/contoso_sales.csv'\n"
     ]
    }
   ],
   "source": [
    "# Whole Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files\",\n",
    "    target_path=\"Files/\"\n",
    ")\n",
    "\n",
    "# Individual Subfolder inside a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files/Contoso\",\n",
    "    target_path=\"Files/Contoso\"\n",
    ")\n",
    "\n",
    "# Specific File in a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files/Contoso/contoso_sales.csv\",\n",
    "    target_path=\"Files/Contoso/contoso_sales.csv\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GitHub (Public Repo)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole GitHub repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Files/GitHub/Polars-Cookbook\"\n",
    ")\n",
    "\n",
    "# Single Table (Delta) in Repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Tables/github_venture_funding_deals_delta\",\n",
    "    folder_path=\"data/venture_funding_deals_delta\"\n",
    ")\n",
    "\n",
    "# Specific folder from GitHub repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Files/GitHub/data\",\n",
    "    folder_path=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GitHub (Private Repo)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_token = os.getenv(\"GH_PERSONAL_ACCESS_TOKEN\")\n",
    "github_username = os.getenv(\"GH_USERNAME\")\n",
    "gh_repo_name = os.getenv(\"GH_REPO_NAME\")\n",
    "\n",
    "# Whole GitHub private repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github_private\",\n",
    "    github_token=github_token,\n",
    "    github_username=github_username,\n",
    "    repo_name=gh_repo_name,\n",
    "    target_path=f\"Files/GitHub/{gh_repo_name}\"\n",
    ")\n",
    "\n",
    "# Specific folder from GitHub private repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github_private\",\n",
    "    github_token=github_token,\n",
    "    github_username=github_username,\n",
    "    repo_name=gh_repo_name,\n",
    "    target_path=\"Files/GitHub/data\",\n",
    "    folder_path=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Azure DevOps (Private Repo)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_url = os.getenv(\"ADO_ORGANIZATIONAL_URL\")\n",
    "personal_access_token = os.getenv(\"ADO_PERSONAL_ACCESS_TOKEN\")\n",
    "project_name = os.getenv(\"ADO_PROJECT_NAME\")\n",
    "repo_name = os.getenv(\"ADO_REPO_NAME\")\n",
    "\n",
    "# Whole Azure DevOps repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"azure_devops\",\n",
    "    project_name=project_name,\n",
    "    repo_name=repo_name,\n",
    "    organization_url=organization_url,\n",
    "    personal_access_token=personal_access_token,\n",
    "    target_path=f\"Files/AzureDevOps/{repo_name}\",\n",
    ")\n",
    "\n",
    "# Specific folder from Azure DevOps repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"azure_devops\",\n",
    "    project_name=project_name,\n",
    "    repo_name=repo_name,\n",
    "    organization_url=organization_url,\n",
    "    personal_access_token=personal_access_token,\n",
    "    target_path=\"Files/AzureDevOps/data\",\n",
    "    folder_path=\"/data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **List Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List All Items in Lakehouse\n",
    "OneLakeUtils.list_items(\n",
    "    file_system_client=file_system_client\n",
    "    ,lakehouse_id=lakehouse_id\n",
    "    ,target_directory_path=\"Tables\" # Tables or Files\n",
    "    #  ,print_output= True # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DeltaLake Table Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read Table from Lakehouse into a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────┬─────────────────┬──────────────────────┬───┬──────────────────────┬───────────────┐\n",
       "│       Company        │     Amount      │    Lead investors    │ … │       Industry       │ Date reported │\n",
       "│       varchar        │     varchar     │       varchar        │   │       varchar        │    varchar    │\n",
       "├──────────────────────┼─────────────────┼──────────────────────┼───┼──────────────────────┼───────────────┤\n",
       "│ OpenAI               │ $10,000,000,000 │ Microsoft            │ … │ Artificial intelli…  │ 1/23/23       │\n",
       "│ Stripe               │ $6,500,000,000  │ n/a                  │ … │ Fintech              │ 3/15/23       │\n",
       "│ Inflection AI        │ $1,300,000,000  │ Microsoft, Reid Ho…  │ … │ Artificial intelli…  │ 6/29/23       │\n",
       "│ Anthropic            │ $1,250,000,000  │ Amazon               │ … │ Artificial intelli…  │ 9/25/23       │\n",
       "│ Generate Capital     │ $1,030,900,000  │ n/a                  │ … │ Energy               │ 1/6/23        │\n",
       "│ Redwood Materials    │ $1,000,000,000  │ Goldman Sachs Asse…  │ … │ Renewable energy     │ 8/29/23       │\n",
       "│ Stack AV             │ $1,000,000,000  │ SoftBand Group       │ … │ Autonomous vehicles  │ 9/7/23        │\n",
       "│ SandboxAQ            │ $500,000,000    │ n/a                  │ … │ Artifical intellig…  │ 2/14/23       │\n",
       "│ Lessen               │ $500,000,000    │ n/a                  │ … │ Real estate          │ 1/11/23       │\n",
       "│ Rippling             │ $500,000,000    │ Greenoaks            │ … │ Human resources      │ 3/17/23       │\n",
       "│   ·                  │      ·          │  ·                   │ · │       ·              │    ·          │\n",
       "│   ·                  │      ·          │  ·                   │ · │       ·              │    ·          │\n",
       "│   ·                  │      ·          │  ·                   │ · │       ·              │    ·          │\n",
       "│ BitGo                │ $100,000,000    │ n/a                  │ … │ Cryptocurrency       │ 8/16/23       │\n",
       "│ Modular              │ $100,000,000    │ General Catalyst     │ … │ Artificial intelli…  │ 8/24/23       │\n",
       "│ Apollo.io            │ $100,000,000    │ Bain Capital Ventu…  │ … │ Sales                │ 8/29/23       │\n",
       "│ Beta Bionics         │ $100,000,000    │ Sands Capital, Ome…  │ … │ Health care          │ 8/30/23       │\n",
       "│ Professional Fight…  │ $100,000,000    │ SRJ Sports Investm…  │ … │ Sports               │ 8/30/23       │\n",
       "│ Inceptive            │ $100,000,000    │ NVentures, Andrees…  │ … │ Biotech              │ 9/7/23        │\n",
       "│ Vesper Energy        │ $100,000,000    │ GCM Grosvenor        │ … │ Energy               │ 9/13/23       │\n",
       "│ Writer               │ $100,000,000    │ Iconiq Growth        │ … │ Artificial intelli…  │ 9/18/23       │\n",
       "│ Pryon                │ $100,000,000    │ US Innovative Tech…  │ … │ Artificial intelli…  │ 9/19/23       │\n",
       "│ Openly               │ $100,000,000    │ Eden Global Partners │ … │ Insurance            │ 9/21/23       │\n",
       "├──────────────────────┴─────────────────┴──────────────────────┴───┴──────────────────────┴───────────────┤\n",
       "│ 171 rows (20 shown)                                                                  6 columns (5 shown) │\n",
       "└──────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fabric_remote_tools import FabricAuth, OneLakeUtils\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "\n",
    "# Authenticate and obtain access token\n",
    "file_system_client = FabricAuth().get_ClientSecretCredential()\n",
    "\n",
    "# Read Table from Lakehouse into Dataframe\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\")\n",
    "lakehouse_name = os.getenv(\"LAKEHOUSE_NAME\")\n",
    "table_name = \"Tables/venture_funding_deals_delta\"\n",
    "table_path = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/{lakehouse_name}.Lakehouse/{table_name}\"\n",
    "\n",
    "df = OneLakeUtils().read_deltalake(\n",
    "    file_system_client=file_system_client,\n",
    "    table_path=table_path,\n",
    "    engine='duckdb',  # Supported options: 'duckdb', 'polars'\n",
    "    # version=11,  # Optional: specify the version to read\n",
    "    # row_limit=10  # Optional\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query DataFrame with DuckDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install magic_duckdb --upgrade --quiet\n",
    "%load_ext magic_duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>null</th>\n",
       "      <th>key</th>\n",
       "      <th>default</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amount</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead investors</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valuation</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Industry</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Date reported</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      column_name column_type null   key default extra\n",
       "0         Company     VARCHAR  YES  None    None  None\n",
       "1          Amount     VARCHAR  YES  None    None  None\n",
       "2  Lead investors     VARCHAR  YES  None    None  None\n",
       "3       Valuation     VARCHAR  YES  None    None  None\n",
       "4        Industry     VARCHAR  YES  None    None  None\n",
       "5   Date reported     VARCHAR  YES  None    None  None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dql\n",
    "PRAGMA disable_print_progress_bar;\n",
    "SUMMARIZE df;\n",
    "DESCRIBE SELECT * FROM df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count\n",
       "0     20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dql\n",
    "CREATE OR REPLACE TABLE df_tranf AS \n",
    "    SELECT *\n",
    "    FROM df\n",
    "    LIMIT 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write DataFrame to Lakehouse as a Delta Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deltalake.writer import write_deltalake\n",
    "import duckdb\n",
    "import pyarrow\n",
    "import polars as pl\n",
    "\n",
    "# Write DataFrame to Lakehouse\n",
    "write_deltalake(\n",
    "    table_or_uri=table_path\n",
    "    ,storage_options=file_system_client\n",
    "    # ,data=df.to_arrow() # Polars DF\n",
    "    ,data=duckdb.sql(\"SELECT * FROM df_tranf\").arrow() # DuckDB (arrow DF)\n",
    "    ,mode=\"append\" # Supported options: 'append', 'overwrite'\n",
    "    ,engine=\"rust\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DESCRIBE HISTORY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>clientVersion</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-14 19:15:06.777</td>\n",
       "      <td>CREATE TABLE</td>\n",
       "      <td>{'mode': 'ErrorIfExists', 'protocol': '{\"minRe...</td>\n",
       "      <td>delta-rs.0.15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp     operation  \\\n",
       "0 2023-10-14 19:15:06.777  CREATE TABLE   \n",
       "\n",
       "                                 operationParameters    clientVersion  version  \n",
       "0  {'mode': 'ErrorIfExists', 'protocol': '{\"minRe...  delta-rs.0.15.0        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deltalake import DeltaTable\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the DeltaTable\n",
    "dt = DeltaTable(table_path)\n",
    "\n",
    "# Retrieve the full history of the DeltaTable\n",
    "history = dt.history()\n",
    "\n",
    "# Convert the history list to a pandas DataFrame\n",
    "history_df = pd.DataFrame(history)\n",
    "\n",
    "# Parse the timestamp column\n",
    "history_df['timestamp'] = pd.to_datetime(history_df['timestamp'], unit='ms')\n",
    "\n",
    "# Display the DataFrame, sorted by version in descending order\n",
    "display(history_df.sort_values(by='version', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Download Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../fabric_remote_tools/main.py\n",
    "\n",
    "# Download a single table\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    target_file_path=\"Tables/venture_funding_deals_delta\",\n",
    "    lakehouse_id=lakehouse_id\n",
    ")\n",
    "\n",
    "# Download a single file\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    target_file_path=\"Files/Contoso/contoso_sales.csv\",\n",
    "    lakehouse_id=lakehouse_id\n",
    ")\n",
    "\n",
    "# Download a subfolder\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    target_file_path=\"Files/Contoso/\",\n",
    "    lakehouse_id=lakehouse_id\n",
    ")\n",
    "\n",
    "# Download all tables\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    target_file_path=\"Tables/\",\n",
    "    lakehouse_id=lakehouse_id\n",
    ")\n",
    "\n",
    "# Download all files\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    target_file_path=\"Files/\",\n",
    "    lakehouse_id=lakehouse_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Delete Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a single table\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Tables/venture_funding_deals_delta\"\n",
    ")\n",
    "\n",
    "# Delete a single file\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Files/Contoso/contoso_sales.csv\"\n",
    ")\n",
    "\n",
    "# Delete a subfolder\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Files/Contoso\"\n",
    ")\n",
    "\n",
    "# Delete all tables\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Tables/\"\n",
    ")\n",
    "\n",
    "# Delete all files\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Files/\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
