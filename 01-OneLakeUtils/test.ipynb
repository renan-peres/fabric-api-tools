{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"fabric_remote_tools: OneLake CRUD Operations\"\n",
    "author: \"Renan Peres\"\n",
    "date: \"July 01, 2024\"\n",
    "format:\n",
    "    html:\n",
    "        theme: \n",
    "            light: flatly\n",
    "            dark: darkly\n",
    "        highlight-style: dracula\n",
    "        code-fold: show\n",
    "        code-tools: \n",
    "            source: true\n",
    "            toggle: true\n",
    "            # caption: none\n",
    "        code-copy: true\n",
    "        code-overflow: wrap\n",
    "        smooth-scroll: true       \n",
    "        page-layout: full\n",
    "        toc: true\n",
    "        toc-location: left\n",
    "        lightbox: true\n",
    "    ipynb:\n",
    "        output-file: output-file: \"fabric_remote_tools-OneLake-CRUD-Operations.ipynb\"\n",
    "        highlight-style: dracula\n",
    "        code-fold: show\n",
    "    pdf: default\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install https://github.com/renan-peres/fabric-remote-tools/raw/main/fabric_remote_tools-0.1.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Modules & Authenticate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabric_remote_tools import FabricAuth, OneLakeUtils\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load Fabric Environmet Variables (.env File)\n",
    "account_name = os.getenv(\"ACCOUNT_NAME\")\n",
    "workspace_id = os.getenv(\"WORKSPACE_ID\")\n",
    "lakehouse_id = os.getenv(\"LAKEHOUSE_ID\")\n",
    "\n",
    "# Get Authentication Token\n",
    "token = FabricAuth.get_service_principal_token()\n",
    "\n",
    "# Get File System Client\n",
    "file_system_client = FabricAuth.get_file_system_client(token, account_name, workspace_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Write to Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Local Tables (Delta)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Table\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Tables/venture_funding_deals_delta\",\n",
    "    target_path=\"Tables/local_venture_funding_deals_delta\"\n",
    ")\n",
    "\n",
    "# Multiple Tables in a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Tables\",\n",
    "    target_path=\"Tables/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Local Files/Folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files\",\n",
    "    target_path=\"Files/\"\n",
    ")\n",
    "\n",
    "# Individual Subfolder inside a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files/Contoso\",\n",
    "    target_path=\"Files/Contoso\"\n",
    ")\n",
    "\n",
    "# Specific File in a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files/Contoso/contoso_sales.csv\",\n",
    "    target_path=\"Files/Contoso/contoso_sales.csv\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GitHub (Public Repo)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole GitHub repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Files/GitHub/Polars-Cookbook\"\n",
    ")\n",
    "\n",
    "# Single Table (Delta) in Repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Tables/github_venture_funding_deals_delta\",\n",
    "    folder_path=\"data/venture_funding_deals_delta\"\n",
    ")\n",
    "\n",
    "# Specific folder from GitHub repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Files/GitHub/data\",\n",
    "    folder_path=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GitHub (Private Repo)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_token = os.getenv(\"GITHUB_PERSONAL_ACCESS_TOKEN\")\n",
    "github_username = os.getenv(\"GITHUB_USERNAME\")\n",
    "gh_repo_name = os.getenv(\"GITHUB_REPO_NAME\")\n",
    "\n",
    "# Whole GitHub private repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github_private\",\n",
    "    github_token=github_token,\n",
    "    github_username=github_username,\n",
    "    repo_name=gh_repo_name,\n",
    "    target_path=f\"Files/GitHub/{gh_repo_name}\"\n",
    ")\n",
    "\n",
    "# Specific folder from GitHub private repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github_private\",\n",
    "    github_token=github_token,\n",
    "    github_username=github_username,\n",
    "    repo_name=gh_repo_name,\n",
    "    target_path=\"Files/GitHub/data\",\n",
    "    folder_path=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Azure DevOps (Private Repo)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_url = os.getenv(\"ORGANIZATIONAL_URL\")\n",
    "personal_access_token = os.getenv(\"PERSONAL_ACCESS_TOKEN\")\n",
    "project_name = os.getenv(\"PROJECT_NAME\")\n",
    "repo_name = os.getenv(\"REPO_NAME\")\n",
    "\n",
    "# Whole Azure DevOps repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"azure_devops\",\n",
    "    project_name=project_name,\n",
    "    repo_name=repo_name,\n",
    "    organization_url=organization_url,\n",
    "    personal_access_token=personal_access_token,\n",
    "    target_path=f\"Files/AzureDevOps/{repo_name}\",\n",
    ")\n",
    "\n",
    "# Specific folder from Azure DevOps repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"azure_devops\",\n",
    "    project_name=project_name,\n",
    "    repo_name=repo_name,\n",
    "    organization_url=organization_url,\n",
    "    personal_access_token=personal_access_token,\n",
    "    target_path=\"Files/AzureDevOps/data\",\n",
    "    folder_path=\"/data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **List Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List All Items in Lakehouse\n",
    "OneLakeUtils.list_items(\n",
    "    file_system_client=file_system_client\n",
    "    ,lakehouse_id=lakehouse_id\n",
    "    ,target_directory_path=\"Tables\" # Tables or Files\n",
    "    #  ,print_output= True # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Delta Table Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read Delta Table from Lakehouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64fb5c42d7e497ba3714b58ff6b4c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┌──────────────────────┬──────────────┬──────────────────────┬───┬───────────────┬──────┬───────┬───────┐\n",
       "│       Company        │    Amount    │    Lead investors    │ … │ Date reported │ Day  │ Month │ Year  │\n",
       "│       varchar        │   varchar    │       varchar        │   │    varchar    │ int8 │ int8  │ int32 │\n",
       "├──────────────────────┼──────────────┼──────────────────────┼───┼───────────────┼──────┼───────┼───────┤\n",
       "│ Rapport Therapeutics │ $100,000,000 │ Third Rock Venture…  │ … │ 3/7/23        │    7 │     3 │  2023 │\n",
       "│ Character.AI         │ $150,000,000 │ Andreessen Horowitz  │ … │ 3/21/23       │   21 │     3 │  2023 │\n",
       "│ Palmetto             │ $150,000,000 │ TPG Rise Climate     │ … │ 3/6/23        │    6 │     3 │  2023 │\n",
       "│ Consensus            │ $110,000,000 │ Sumeru Equity Part…  │ … │ 3/8/23        │    8 │     3 │  2023 │\n",
       "│ Bicara Therapeutics  │ $108,000,000 │ Red Tree Venture C…  │ … │ 3/6/23        │    6 │     3 │  2023 │\n",
       "│ CARGO Therapeutics   │ $200,000,000 │ Third Rock Venture…  │ … │ 3/1/23        │    1 │     3 │  2023 │\n",
       "│ Humane               │ $100,000,000 │ Kindred Ventures     │ … │ 3/8/23        │    8 │     3 │  2023 │\n",
       "│ Rippling             │ $500,000,000 │ Greenoaks            │ … │ 3/17/23       │   17 │     3 │  2023 │\n",
       "│ Amogy                │ $139,000,000 │ SK Innovation        │ … │ 3/22/23       │   22 │     3 │  2023 │\n",
       "│ Adept AI             │ $350,000,000 │ General Catalyst, …  │ … │ 3/14/23       │   14 │     3 │  2023 │\n",
       "│    ·                 │      ·       │  ·                   │ · │    ·          │    · │     · │    ·  │\n",
       "│    ·                 │      ·       │  ·                   │ · │    ·          │    · │     · │    ·  │\n",
       "│    ·                 │      ·       │  ·                   │ · │    ·          │    · │     · │    ·  │\n",
       "│ Harbinger Health     │ $140,000,000 │ n/a                  │ … │ 9/25/23       │   25 │     9 │  2023 │\n",
       "│ EquipmentShare       │ $150,000,000 │ BDT & MSD Partners   │ … │ 9/13/23       │   13 │     9 │  2023 │\n",
       "│ PayJoy               │ $150,000,000 │ Warburg Pincus       │ … │ 9/5/23        │    5 │     9 │  2023 │\n",
       "│ Alto Pharmacy        │ $120,000,000 │ n/a                  │ … │ 9/25/23       │   25 │     9 │  2023 │\n",
       "│ D-Matrix             │ $110,000,000 │ Temasek              │ … │ 9/6/23        │    6 │     9 │  2023 │\n",
       "│ Inceptive            │ $100,000,000 │ NVentures, Andrees…  │ … │ 9/7/23        │    7 │     9 │  2023 │\n",
       "│ Vesper Energy        │ $100,000,000 │ GCM Grosvenor        │ … │ 9/13/23       │   13 │     9 │  2023 │\n",
       "│ Writer               │ $100,000,000 │ Iconiq Growth        │ … │ 9/18/23       │   18 │     9 │  2023 │\n",
       "│ Pryon                │ $100,000,000 │ US Innovative Tech…  │ … │ 9/19/23       │   19 │     9 │  2023 │\n",
       "│ Openly               │ $100,000,000 │ Eden Global Partners │ … │ 9/21/23       │   21 │     9 │  2023 │\n",
       "├──────────────────────┴──────────────┴──────────────────────┴───┴───────────────┴──────┴───────┴───────┤\n",
       "│ 342 rows (20 shown)                                                               9 columns (7 shown) │\n",
       "└───────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fabric_remote_tools import FabricAuth, OneLakeUtils\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "\n",
    "# Authenticate and obtain access token\n",
    "file_system_client = FabricAuth().get_client_secret_token()\n",
    "\n",
    "# Read Table from Lakehouse into Dataframe\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\")\n",
    "lakehouse_name = os.getenv(\"LAKEHOUSE_NAME\")\n",
    "table_name = \"Tables/venture_funding_deals_delta_partitioned\"\n",
    "table_path = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/{lakehouse_name}.Lakehouse/{table_name}\"\n",
    "\n",
    "df = OneLakeUtils().read_delta_from_fabric_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    table_path=table_path,\n",
    "    engine='duckdb',  # Supported options: 'duckdb', 'polars'\n",
    "    version=11,  # Optional: specify the version to read\n",
    "    # row_limit=10  # Optional\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write DataFrame to Lakehouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deltalake.writer import write_deltalake\n",
    "import duckdb\n",
    "import pyarrow\n",
    "import polars as pl\n",
    "\n",
    "# Write DataFrame to Lakehouse\n",
    "write_deltalake(\n",
    "    table_or_uri=table_path\n",
    "    ,storage_options=file_system_client\n",
    "    # ,data=df.to_arrow() # Polars DF\n",
    "    ,data=df.arrow() # DuckDB (arrow DF)\n",
    "    ,mode=\"append\" # Supported options: 'append', 'overwrite'\n",
    "    ,engine=\"rust\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DESCRIBE HISTORY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>clientVersion</th>\n",
       "      <th>version</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>engineInfo</th>\n",
       "      <th>txnId</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-02 19:57:56.736</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Overwrite', 'partitionBy': '[\"Month\"]'}</td>\n",
       "      <td>delta-rs.0.18.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-02 19:55:33.151</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Append', 'partitionBy': '[\"Month\"]'}</td>\n",
       "      <td>delta-rs.0.18.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-02 19:53:09.165</td>\n",
       "      <td>VACUUM END</td>\n",
       "      <td>{'status': 'COMPLETED'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>SnapshotIsolation</td>\n",
       "      <td>True</td>\n",
       "      <td>Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...</td>\n",
       "      <td>33d20b2a-18af-4181-be73-16fa36691665</td>\n",
       "      <td>{'numDeletedFiles': '0', 'numVacuumedDirectori...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-02 19:53:07.140</td>\n",
       "      <td>VACUUM START</td>\n",
       "      <td>{'retentionCheckEnabled': True, 'defaultRetent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>SnapshotIsolation</td>\n",
       "      <td>True</td>\n",
       "      <td>Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...</td>\n",
       "      <td>753c18cb-da83-496f-93b8-c276cf758f64</td>\n",
       "      <td>{'numFilesToDelete': '0', 'sizeOfDataToDelete'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-02 19:51:21.406</td>\n",
       "      <td>VACUUM END</td>\n",
       "      <td>{'status': 'COMPLETED'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SnapshotIsolation</td>\n",
       "      <td>True</td>\n",
       "      <td>Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...</td>\n",
       "      <td>60e404d2-1717-4718-916e-029fd5e6a70b</td>\n",
       "      <td>{'numDeletedFiles': '0', 'numVacuumedDirectori...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp     operation  \\\n",
       "0 2024-07-02 19:57:56.736         WRITE   \n",
       "1 2024-07-02 19:55:33.151         WRITE   \n",
       "2 2024-07-02 19:53:09.165    VACUUM END   \n",
       "3 2024-07-02 19:53:07.140  VACUUM START   \n",
       "4 2024-07-02 19:51:21.406    VACUUM END   \n",
       "\n",
       "                                 operationParameters    clientVersion  \\\n",
       "0  {'mode': 'Overwrite', 'partitionBy': '[\"Month\"]'}  delta-rs.0.18.0   \n",
       "1     {'mode': 'Append', 'partitionBy': '[\"Month\"]'}  delta-rs.0.18.0   \n",
       "2                            {'status': 'COMPLETED'}              NaN   \n",
       "3  {'retentionCheckEnabled': True, 'defaultRetent...              NaN   \n",
       "4                            {'status': 'COMPLETED'}              NaN   \n",
       "\n",
       "   version  readVersion     isolationLevel isBlindAppend  \\\n",
       "0       12          NaN                NaN           NaN   \n",
       "1       11          NaN                NaN           NaN   \n",
       "2       10          9.0  SnapshotIsolation          True   \n",
       "3        9          8.0  SnapshotIsolation          True   \n",
       "4        8          7.0  SnapshotIsolation          True   \n",
       "\n",
       "                                          engineInfo  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...   \n",
       "3  Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...   \n",
       "4  Apache-Spark/3.4.1.5.3.20240528.1 Delta-Lake/2...   \n",
       "\n",
       "                                  txnId  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2  33d20b2a-18af-4181-be73-16fa36691665   \n",
       "3  753c18cb-da83-496f-93b8-c276cf758f64   \n",
       "4  60e404d2-1717-4718-916e-029fd5e6a70b   \n",
       "\n",
       "                                    operationMetrics tags  \n",
       "0                                                NaN  NaN  \n",
       "1                                                NaN  NaN  \n",
       "2  {'numDeletedFiles': '0', 'numVacuumedDirectori...  NaN  \n",
       "3  {'numFilesToDelete': '0', 'sizeOfDataToDelete'...  NaN  \n",
       "4  {'numDeletedFiles': '0', 'numVacuumedDirectori...  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deltalake import DeltaTable\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the DeltaTable\n",
    "dt = DeltaTable(table_path)\n",
    "\n",
    "# Retrieve the full history of the DeltaTable\n",
    "history = dt.history()\n",
    "\n",
    "# Convert the history list to a pandas DataFrame\n",
    "history_df = pd.DataFrame(history)\n",
    "\n",
    "# Parse the timestamp column\n",
    "history_df['timestamp'] = pd.to_datetime(history_df['timestamp'], unit='ms')\n",
    "\n",
    "# Display the DataFrame, sorted by version in descending order\n",
    "display(history_df.sort_values(by='version', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Download Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client\n",
    "    ,lakehouse_id=lakehouse_id\n",
    "    # ,target_file_path=\"Tables/venture_funding_deals\" # Single Table\n",
    "    ,target_file_path=\"Tables/\" # All Tables\n",
    ")\n",
    "\n",
    "# Files\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client\n",
    "    ,lakehouse_id=lakehouse_id\n",
    "    # ,target_file_path=\"Files/Contoso/contoso_sales.csv\" # Single File\n",
    "    # ,target_file_path=\"Files/Contoso/\" # Subfolder\n",
    "    ,target_file_path=\"Files/\" # All Subfolders & Files\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Delete Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client\n",
    "    ,lakehouse_id=lakehouse_id\n",
    "    # ,lakehouse_dir_path=\"Tables/venture_funding_deals_delta\" # Single Table\n",
    "    ,lakehouse_dir_path=\"Tables/\" # All Tables\n",
    ")\n",
    "\n",
    "# Files\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client \n",
    "    ,lakehouse_id=lakehouse_id\n",
    "    # ,lakehouse_dir_path=\"Files/Contoso/contoso_sales.csv\" # Single File\n",
    "    # ,lakehouse_dir_path=\"Files/Contoso\" # Subfolder\n",
    "    ,lakehouse_dir_path=\"Files/\" # All Subfolders & Files\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
